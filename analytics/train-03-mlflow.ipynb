{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228f0b0d-dff2-4cb6-9348-14cd5ce0f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c874b7c8-282f-40ac-9e8c-2f1d1b3145fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225402d5-108d-43a8-a3a6-ed404668dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('../data/random-users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7714ba1-f306-41d3-ab1f-2e395927e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.read_csv('../data/random-logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d03771-9e4b-4aea-a0f3-c4bb74521e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_required_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def process_feature_string(feature_string):\n",
    "\n",
    "        features = [f.strip() for f in feature_string.split(',')]\n",
    "        return {f'required_feature_{feature}': 1 for feature in features}\n",
    "    \n",
    "    feature_dicts = df['required_features'].apply(process_feature_string)\n",
    "    df = df.drop('required_features', axis=1)\n",
    "    record_dicts = df.to_dict('records')\n",
    "    \n",
    "    for record, feature_dict in zip(record_dicts, feature_dicts):\n",
    "        record.update(feature_dict)\n",
    "    \n",
    "    return record_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce182f6-437c-47df-8a6f-4e32c5d7a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_features(df_users, df_logs, cutoff_date):\n",
    "    df_logs_filtered = df_logs[df_logs['timestamp'] < cutoff_date].copy()\n",
    "    \n",
    "    engagement_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'timestamp': ['count', 'nunique'],  # Total actions and unique days\n",
    "        'duration_seconds': ['sum', 'mean', 'std']  # Time spent metrics\n",
    "    }).round(2)\n",
    "    \n",
    "    engagement_metrics.columns = [\n",
    "        'total_actions',\n",
    "        'active_days',\n",
    "        'total_duration',\n",
    "        'avg_duration',\n",
    "        'std_duration'\n",
    "    ]\n",
    "    \n",
    "    # Action category distribution\n",
    "    category_counts = df_logs_filtered.groupby(['user_id', 'action_category']).size().unstack(\n",
    "        fill_value=0\n",
    "    ).add_prefix('category_')\n",
    "    \n",
    "    # Action type distribution (top 10 most common)\n",
    "    top_actions = df_logs_filtered['action_type'].value_counts().nlargest(10).index\n",
    "    action_counts = df_logs_filtered[df_logs_filtered['action_type'].isin(top_actions)]\\\n",
    "        .groupby(['user_id', 'action_type']).size().unstack(fill_value=0).add_prefix('action_')\n",
    "    \n",
    "    # Time-based features\n",
    "    df_logs_filtered['hour'] = df_logs_filtered['timestamp'].dt.hour\n",
    "    time_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'hour': lambda x: len(x[x.between(9, 17)]) / len(x)  # Fraction of activity during business hours\n",
    "    }).round(2)\n",
    "    time_metrics.columns = ['business_hours_ratio']\n",
    "    \n",
    "    # Activity patterns\n",
    "    df_logs_filtered['days_since_signup'] = (\n",
    "        df_logs_filtered['timestamp'] - \n",
    "        df_logs_filtered['user_id'].map(df_users.set_index('user_id')['signup_date'])\n",
    "    ).dt.days\n",
    "    \n",
    "    recency_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'days_since_signup': ['min', 'max']\n",
    "    }).round(2)\n",
    "    recency_metrics.columns = ['days_to_first_action', 'days_to_last_action']\n",
    "    \n",
    "    # Advanced engagement metrics\n",
    "    df_logs_filtered['prev_timestamp'] = df_logs_filtered.groupby('user_id')['timestamp'].shift(1)\n",
    "    df_logs_filtered['time_between_actions'] = (\n",
    "        df_logs_filtered['timestamp'] - df_logs_filtered['prev_timestamp']\n",
    "    ).dt.total_seconds() / 3600  # Convert to hours\n",
    "    \n",
    "    engagement_patterns = df_logs_filtered.groupby('user_id').agg({\n",
    "        'time_between_actions': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    engagement_patterns.columns = ['avg_hours_between_actions', 'std_hours_between_actions']\n",
    "    \n",
    "    # Feature importance indicators\n",
    "    feature_exploration = df_logs_filtered[\n",
    "        df_logs_filtered['action_type'] == 'view_features'\n",
    "    ].groupby('user_id').size().to_frame('feature_views')\n",
    "    \n",
    "    # Combine all features\n",
    "    log_features = pd.concat([\n",
    "        engagement_metrics,\n",
    "        category_counts,\n",
    "        action_counts,\n",
    "        time_metrics,\n",
    "        recency_metrics,\n",
    "        engagement_patterns,\n",
    "        feature_exploration\n",
    "    ], axis=1).reset_index()\n",
    "    \n",
    "    # Fill NaN values with 0 for new users or users with missing metrics\n",
    "    log_features = log_features.fillna(0)\n",
    "    \n",
    "    return log_features\n",
    "\n",
    "\n",
    "def prepare_lead_scoring_data(df_users, df_logs, train_end_date, val_end_date):\n",
    "    df_users = df_users.copy()\n",
    "    df_logs = df_logs.copy()\n",
    "    \n",
    "    df_users['signup_date'] = pd.to_datetime(df_users['signup_date'])\n",
    "    df_logs['timestamp'] = pd.to_datetime(df_logs['timestamp'])\n",
    "    \n",
    "    train_end_date = pd.to_datetime(train_end_date)\n",
    "    val_end_date = pd.to_datetime(val_end_date)\n",
    "    \n",
    "    train_mask = df_users['signup_date'] < train_end_date\n",
    "    val_mask = (df_users['signup_date'] >= train_end_date) & (df_users['signup_date'] < val_end_date)\n",
    "    test_mask = df_users['signup_date'] >= val_end_date\n",
    "    \n",
    "    df_train = df_users[train_mask].copy()\n",
    "    df_val = df_users[val_mask].copy()\n",
    "    df_test = df_users[test_mask].copy()\n",
    "    \n",
    "    train_features = create_log_features(df_users, df_logs, train_end_date)\n",
    "    val_features = create_log_features(df_users, df_logs, val_end_date)\n",
    "    test_features = create_log_features(df_users, df_logs, df_logs['timestamp'].max())\n",
    "\n",
    "    df_train = df_train.merge(train_features, on='user_id', how='left')\n",
    "    df_val = df_val.merge(val_features, on='user_id', how='left')\n",
    "    df_test = df_test.merge(test_features, on='user_id', how='left')\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e21c5b0-a1ae-4a00-91b1-4bd3d29d469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = prepare_lead_scoring_data(\n",
    "    df_users,\n",
    "    df_logs,\n",
    "    train_end_date='2024-03-01',\n",
    "    val_end_date='2024-03-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be980606-f060-44ab-a955-465c3113fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def prepare_features(df, dv=None, fit=True):\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    date_columns = ['signup_date', 'conversion_date']\n",
    "    exclude_columns = ['user_id', 'converted'] + date_columns\n",
    "    \n",
    "    df = df.drop(columns=exclude_columns)\n",
    "    df = df.fillna(0)\n",
    "    feature_dict = preprocess_required_features(df)\n",
    "    \n",
    "    if dv is None:\n",
    "        dv = DictVectorizer(sparse=True)\n",
    "    \n",
    "    if fit:\n",
    "        X = dv.fit_transform(feature_dict)\n",
    "    else:\n",
    "        X = dv.transform(feature_dict)\n",
    "    \n",
    "    return X, dv\n",
    "\n",
    "X_train, dv = prepare_features(df_train, fit=True)\n",
    "X_val, _ = prepare_features(df_val, dv=dv, fit=False)\n",
    "X_test, _ = prepare_features(df_test, dv=dv, fit=False)\n",
    "\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc990e3a-7e4e-4c53-99ed-1922ca8dd02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:36:10 INFO mlflow.tracking.fluent: Experiment with name 'logistic_regression_tuning' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/lld-lead-scoring/analytics/mlruns/1', creation_time=1731591370971, experiment_id='1', last_update_time=1731591370971, lifecycle_stage='active', name='logistic_regression_tuning', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set up MLflow - this will create an 'mlruns' directory in your current directory\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"logistic_regression_tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6baa71-cd2f-4b11-a870-f7005a1879a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657e6cf4-49c7-4eb2-bc53-f79a70f5333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "579a70cb-0a8d-49b6-8548-e26f1643fc8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:21 INFO mlflow.tracking._tracking_service.client: 🏃 View run inquisitive-wolf-385 at: http://localhost:5000/#/experiments/1/runs/f46523ad63cb4de9a6a996813013d061.\n",
      "2024/11/14 13:47:21 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.389, Val AUC: 0.408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:23 INFO mlflow.tracking._tracking_service.client: 🏃 View run beautiful-deer-122 at: http://localhost:5000/#/experiments/1/runs/81984db390294b618cef2b974ae7dec9.\n",
      "2024/11/14 13:47:23 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.643, Val AUC: 0.566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:25 INFO mlflow.tracking._tracking_service.client: 🏃 View run marvelous-hound-690 at: http://localhost:5000/#/experiments/1/runs/9f59ee38ced4422c91ad0d802e3c8ba8.\n",
      "2024/11/14 13:47:25 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=saga, penalty=l1:\n",
      "Train AUC: 0.389, Val AUC: 0.409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:28 INFO mlflow.tracking._tracking_service.client: 🏃 View run inquisitive-stag-978 at: http://localhost:5000/#/experiments/1/runs/0f12198f4b2e4cd4b216774eaa296473.\n",
      "2024/11/14 13:47:28 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=saga, penalty=l2:\n",
      "Train AUC: 0.547, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run persistent-calf-322 at: http://localhost:5000/#/experiments/1/runs/ce2166f9af9e44c0a31945b08f77327c.\n",
      "2024/11/14 13:47:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.494, Val AUC: 0.429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:31 INFO mlflow.tracking._tracking_service.client: 🏃 View run carefree-sponge-649 at: http://localhost:5000/#/experiments/1/runs/b2fc52ba2d3d4d4c8bc0057f5e52ddd0.\n",
      "2024/11/14 13:47:31 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.656, Val AUC: 0.592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:34 INFO mlflow.tracking._tracking_service.client: 🏃 View run industrious-mole-538 at: http://localhost:5000/#/experiments/1/runs/ad88bf34d57f472f8dff1073da4ae8e4.\n",
      "2024/11/14 13:47:34 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=saga, penalty=l1:\n",
      "Train AUC: 0.489, Val AUC: 0.426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run skillful-conch-147 at: http://localhost:5000/#/experiments/1/runs/698723fc53954c879d5face8254b7e7d.\n",
      "2024/11/14 13:47:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run unleashed-slug-610 at: http://localhost:5000/#/experiments/1/runs/a455958d26a84e08b9a779bc3fb8582f.\n",
      "2024/11/14 13:47:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.645, Val AUC: 0.583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:40 INFO mlflow.tracking._tracking_service.client: 🏃 View run brawny-hare-976 at: http://localhost:5000/#/experiments/1/runs/41b6af2ed4884e71b65651b4939efe7e.\n",
      "2024/11/14 13:47:40 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.685, Val AUC: 0.586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:42 INFO mlflow.tracking._tracking_service.client: 🏃 View run skittish-shad-286 at: http://localhost:5000/#/experiments/1/runs/a535da4aa6f448938ddfada8341250dc.\n",
      "2024/11/14 13:47:42 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=saga, penalty=l1:\n",
      "Train AUC: 0.543, Val AUC: 0.440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:45 INFO mlflow.tracking._tracking_service.client: 🏃 View run gregarious-moth-702 at: http://localhost:5000/#/experiments/1/runs/592d4ee625674fd385097608f2ed78e9.\n",
      "2024/11/14 13:47:45 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:46 INFO mlflow.tracking._tracking_service.client: 🏃 View run receptive-trout-894 at: http://localhost:5000/#/experiments/1/runs/e7d523d1725f4895a907dc7bcd6ed4ae.\n",
      "2024/11/14 13:47:46 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.674, Val AUC: 0.603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:48 INFO mlflow.tracking._tracking_service.client: 🏃 View run chill-grub-894 at: http://localhost:5000/#/experiments/1/runs/8fd02fb421c741659b0c1ad32fe92497.\n",
      "2024/11/14 13:47:48 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.712, Val AUC: 0.560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run righteous-cow-427 at: http://localhost:5000/#/experiments/1/runs/6fe32eab45e745c293200f5c7e4d3ae8.\n",
      "2024/11/14 13:47:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=saga, penalty=l1:\n",
      "Train AUC: 0.547, Val AUC: 0.440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:47:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:53 INFO mlflow.tracking._tracking_service.client: 🏃 View run casual-pig-683 at: http://localhost:5000/#/experiments/1/runs/9b79d91897b1447b872440d490c510a7.\n",
      "2024/11/14 13:47:53 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run big-crab-922 at: http://localhost:5000/#/experiments/1/runs/ff7adae067424641afdba788ae24a504.\n",
      "2024/11/14 13:47:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.720, Val AUC: 0.570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:47:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:47:57 INFO mlflow.tracking._tracking_service.client: 🏃 View run peaceful-eel-268 at: http://localhost:5000/#/experiments/1/runs/01c6d3a1c906455f8b48d98e4f931471.\n",
      "2024/11/14 13:47:57 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.719, Val AUC: 0.561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:48:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:00 INFO mlflow.tracking._tracking_service.client: 🏃 View run dazzling-perch-42 at: http://localhost:5000/#/experiments/1/runs/e9d5235d685c49e8993830b8f7e211ca.\n",
      "2024/11/14 13:48:00 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=saga, penalty=l1:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:48:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run funny-eel-599 at: http://localhost:5000/#/experiments/1/runs/6df37abcfd5f4b2daef785560e435f7c.\n",
      "2024/11/14 13:48:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:48:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run unique-sloth-163 at: http://localhost:5000/#/experiments/1/runs/ef6b6a8eaf79449588a21890fd30bda4.\n",
      "2024/11/14 13:48:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.722, Val AUC: 0.574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:48:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:06 INFO mlflow.tracking._tracking_service.client: 🏃 View run rumbling-sloth-461 at: http://localhost:5000/#/experiments/1/runs/21df5844f7c845529d2b8daeee28005a.\n",
      "2024/11/14 13:48:06 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.720, Val AUC: 0.560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:48:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:09 INFO mlflow.tracking._tracking_service.client: 🏃 View run unleashed-pug-735 at: http://localhost:5000/#/experiments/1/runs/8261a2640f43424a8f47926f4b928689.\n",
      "2024/11/14 13:48:09 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=saga, penalty=l1:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/14 13:48:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:48:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run serious-doe-710 at: http://localhost:5000/#/experiments/1/runs/d8d8249b28df4950aa8839329c6df2f3.\n",
      "2024/11/14 13:48:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for C in param_grid['C']:\n",
    "    for solver in param_grid['solver']:\n",
    "        for penalty in param_grid['penalty']:\n",
    "            # Skip invalid combinations\n",
    "            if solver == 'liblinear' and penalty not in ['l1', 'l2']:\n",
    "                continue\n",
    "                \n",
    "            # Start an MLflow run\n",
    "            with mlflow.start_run():\n",
    "                # Log parameters\n",
    "                mlflow.log_param(\"C\", C)\n",
    "                mlflow.log_param(\"solver\", solver)\n",
    "                mlflow.log_param(\"penalty\", penalty)\n",
    "                \n",
    "                # Train model\n",
    "                model = LogisticRegression(\n",
    "                    C=C, \n",
    "                    solver=solver,\n",
    "                    penalty=penalty,\n",
    "                    random_state=1,\n",
    "                    max_iter=1000\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Get predictions\n",
    "                train_pred = model.predict_proba(X_train)[:, 1]\n",
    "                val_pred = model.predict_proba(X_val)[:, 1]\n",
    "                \n",
    "                # Calculate AUC\n",
    "                train_auc = roc_auc_score(y_train, train_pred)\n",
    "                val_auc = roc_auc_score(y_val, val_pred)\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"train_auc\", train_auc)\n",
    "                mlflow.log_metric(\"val_auc\", val_auc)\n",
    "                \n",
    "                # Log model\n",
    "                # mlflow.sklearn.log_model(model, \"model\")\n",
    "                pipeline = Pipeline([\n",
    "                    ('vectorizer', dv),\n",
    "                    ('model', best_model)\n",
    "                ])\n",
    "\n",
    "                mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "                \n",
    "                print(f\"Run with C={C}, solver={solver}, penalty={penalty}:\")\n",
    "                print(f\"Train AUC: {train_auc:.3f}, Val AUC: {val_auc:.3f}\\n\")\n",
    "\n",
    "                results.append({\n",
    "                    'C': C,\n",
    "                    'solver': solver,\n",
    "                    'penalty': penalty,\n",
    "                    'train_auc': train_auc,\n",
    "                    'val_auc': val_auc\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57439df3-7a14-4b81-9059-61150c0a630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models by validation AUC:\n",
      "         C     solver penalty  train_auc   val_auc\n",
      "12   0.100  liblinear      l1   0.674355  0.603015\n",
      "5    0.001  liblinear      l2   0.656337  0.592494\n",
      "9    0.010  liblinear      l2   0.685496  0.586387\n",
      "8    0.010  liblinear      l1   0.645429  0.582667\n",
      "20  10.000  liblinear      l1   0.721949  0.574228\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for easy analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('val_auc', ascending=False)\n",
    "\n",
    "print(\"Top 5 models by validation AUC:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eed24e85-526c-4f1d-a148-3375509a5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      "C=0.1, solver=liblinear, penalty=l1\n",
      "Validation AUC: 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 13:38:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/14 13:38:59 INFO mlflow.tracking._tracking_service.client: 🏃 View run best_model at: http://localhost:5000/#/experiments/1/runs/0fa661d274634f378a8dc4d431f366a5.\n",
      "2024/11/14 13:38:59 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters\n",
    "best_params = results_df.iloc[0]\n",
    "print(\"\\nBest parameters:\")\n",
    "print(f\"C={best_params['C']}, solver={best_params['solver']}, penalty={best_params['penalty']}\")\n",
    "print(f\"Validation AUC: {best_params['val_auc']:.3f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "with mlflow.start_run(run_name=\"best_model\"):\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params['C'],\n",
    "        solver=best_params['solver'],\n",
    "        penalty=best_params['penalty'],\n",
    "        random_state=1,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Log best parameters\n",
    "    mlflow.log_params({\n",
    "        \"C\": best_params['C'],\n",
    "        \"solver\": best_params['solver'],\n",
    "        \"penalty\": best_params['penalty']\n",
    "    })\n",
    "    \n",
    "    # Log final metrics\n",
    "    final_train_pred = best_model.predict_proba(X_train)[:, 1]\n",
    "    final_val_pred = best_model.predict_proba(X_val)[:, 1]\n",
    "    final_train_auc = roc_auc_score(y_train, final_train_pred)\n",
    "    final_val_auc = roc_auc_score(y_val, final_val_pred)\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"final_train_auc\": final_train_auc,\n",
    "        \"final_val_auc\": final_val_auc\n",
    "    })\n",
    "    \n",
    "    # Log the final model\n",
    "    mlflow.sklearn.log_model(best_model, \"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bf0ea47-a9f4-43e8-b87c-3ed6403c2f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features with tuned model:\n",
      "                               feature  importance  abs_importance\n",
      "38         expected_student_count=<100    0.129421        0.129421\n",
      "44                lead_source=Referral   -0.127615        0.127615\n",
      "41    lead_source=Education Conference   -0.121131        0.121131\n",
      "17            category_course_creation    0.089542        0.089542\n",
      "60  primary_use_case=Employee Training   -0.084075        0.084075\n",
      "50            organization_size=51-200    0.072476        0.072476\n",
      "20                    category_support    0.061360        0.061360\n",
      "2                 action_create_course    0.059987        0.059987\n",
      "4                  action_invite_users    0.058763        0.058763\n",
      "12           avg_hours_between_actions   -0.056850        0.056850\n"
     ]
    }
   ],
   "source": [
    "# Look at feature importance for the tuned model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': dv.feature_names_,\n",
    "    'importance': best_model.coef_[0],\n",
    "    'abs_importance': np.abs(best_model.coef_[0])\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('abs_importance', ascending=False)\n",
    "\n",
    "print('\\nTop 10 most important features with tuned model:')\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d4d9e1-ade7-446a-af5b-1280a3a973b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = dv.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48027f6c-c009-4924-96a1-bfb1b2b73bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Source Impact on Conversion (sorted by coefficient):\n",
      "                 source  coefficient\n",
      "0        Direct Traffic     0.000000\n",
      "2         Google Search     0.000000\n",
      "5          Social Media     0.000000\n",
      "3   Product Review Site     0.000000\n",
      "1  Education Conference    -0.121131\n",
      "4              Referral    -0.127615\n",
      "\n",
      "Lead Source Distribution in Training Data:\n",
      "lead_source\n",
      "Education Conference    326\n",
      "Product Review Site     278\n",
      "Referral                212\n",
      "Social Media            182\n",
      "Google Search           181\n",
      "Direct Traffic          149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get all features related to lead_source\n",
    "lead_source_features = [f for f in feature_names if 'lead_source=' in f]\n",
    "\n",
    "# Get their coefficients\n",
    "lead_source_coef = pd.DataFrame({\n",
    "    'feature': lead_source_features,\n",
    "    'coefficient': best_model.coef_[0][np.where([f in lead_source_features for f in feature_names])[0]]\n",
    "})\n",
    "\n",
    "# Sort by coefficient value to see most positive to most negative impact\n",
    "lead_source_coef = lead_source_coef.sort_values('coefficient', ascending=False)\n",
    "\n",
    "# Strip the 'lead_source=' prefix for cleaner display\n",
    "lead_source_coef['source'] = lead_source_coef['feature'].str.replace('lead_source=', '')\n",
    "\n",
    "print(\"Lead Source Impact on Conversion (sorted by coefficient):\")\n",
    "print(lead_source_coef[['source', 'coefficient']])\n",
    "\n",
    "# You might also want to see the distribution of lead sources in your data\n",
    "print(\"\\nLead Source Distribution in Training Data:\")\n",
    "print(df_train['lead_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448436ef-6e52-4abb-86e1-ee9447459c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
