{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228f0b0d-dff2-4cb6-9348-14cd5ce0f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c874b7c8-282f-40ac-9e8c-2f1d1b3145fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d863c601-1f27-4603-9155-e8532633e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d21c5a-92dd-4067-a3df-1182c602d205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/lld-lead-scoring/analytics/mlruns/1', creation_time=1731591370971, experiment_id='1', last_update_time=1731591370971, lifecycle_stage='active', name='logistic_regression_tuning', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"logistic_regression_tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225402d5-108d-43a8-a3a6-ed404668dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('../data/random-users.csv')\n",
    "df_logs = pd.read_csv('../data/random-logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d03771-9e4b-4aea-a0f3-c4bb74521e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_required_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def process_feature_string(feature_string):\n",
    "        features = [f.strip() for f in feature_string.split(',')]\n",
    "        return {f'required_feature_{feature}': 1 for feature in features}\n",
    "    \n",
    "    feature_dicts = df['required_features'].apply(process_feature_string)\n",
    "    df = df.drop('required_features', axis=1)\n",
    "    record_dicts = df.to_dict('records')\n",
    "    \n",
    "    for record, feature_dict in zip(record_dicts, feature_dicts):\n",
    "        record.update(feature_dict)\n",
    "    \n",
    "    return record_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce182f6-437c-47df-8a6f-4e32c5d7a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_features(df_users, df_logs, cutoff_date):\n",
    "    df_logs_filtered = df_logs[df_logs['timestamp'] < cutoff_date].copy()\n",
    "    \n",
    "    engagement_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'timestamp': ['count', 'nunique'],  # Total actions and unique days\n",
    "        'duration_seconds': ['sum', 'mean', 'std']  # Time spent metrics\n",
    "    }).round(2)\n",
    "    \n",
    "    engagement_metrics.columns = [\n",
    "        'total_actions',\n",
    "        'active_days',\n",
    "        'total_duration',\n",
    "        'avg_duration',\n",
    "        'std_duration'\n",
    "    ]\n",
    "    \n",
    "    # Action category distribution\n",
    "    category_counts = df_logs_filtered.groupby(['user_id', 'action_category']).size().unstack(\n",
    "        fill_value=0\n",
    "    ).add_prefix('category_')\n",
    "    \n",
    "    # Action type distribution (top 10 most common)\n",
    "    top_actions = df_logs_filtered['action_type'].value_counts().nlargest(10).index\n",
    "    action_counts = df_logs_filtered[df_logs_filtered['action_type'].isin(top_actions)]\\\n",
    "        .groupby(['user_id', 'action_type']).size().unstack(fill_value=0).add_prefix('action_')\n",
    "    \n",
    "    # Time-based features\n",
    "    df_logs_filtered['hour'] = df_logs_filtered['timestamp'].dt.hour\n",
    "    time_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'hour': lambda x: len(x[x.between(9, 17)]) / len(x)  # Fraction of activity during business hours\n",
    "    }).round(2)\n",
    "    time_metrics.columns = ['business_hours_ratio']\n",
    "    \n",
    "    # Activity patterns\n",
    "    df_logs_filtered['days_since_signup'] = (\n",
    "        df_logs_filtered['timestamp'] - \n",
    "        df_logs_filtered['user_id'].map(df_users.set_index('user_id')['signup_date'])\n",
    "    ).dt.days\n",
    "    \n",
    "    recency_metrics = df_logs_filtered.groupby('user_id').agg({\n",
    "        'days_since_signup': ['min', 'max']\n",
    "    }).round(2)\n",
    "    recency_metrics.columns = ['days_to_first_action', 'days_to_last_action']\n",
    "    \n",
    "    # Advanced engagement metrics\n",
    "    df_logs_filtered['prev_timestamp'] = df_logs_filtered.groupby('user_id')['timestamp'].shift(1)\n",
    "    df_logs_filtered['time_between_actions'] = (\n",
    "        df_logs_filtered['timestamp'] - df_logs_filtered['prev_timestamp']\n",
    "    ).dt.total_seconds() / 3600  # Convert to hours\n",
    "    \n",
    "    engagement_patterns = df_logs_filtered.groupby('user_id').agg({\n",
    "        'time_between_actions': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    engagement_patterns.columns = ['avg_hours_between_actions', 'std_hours_between_actions']\n",
    "    \n",
    "    # Feature importance indicators\n",
    "    feature_exploration = df_logs_filtered[\n",
    "        df_logs_filtered['action_type'] == 'view_features'\n",
    "    ].groupby('user_id').size().to_frame('feature_views')\n",
    "    \n",
    "    # Combine all features\n",
    "    log_features = pd.concat([\n",
    "        engagement_metrics,\n",
    "        category_counts,\n",
    "        action_counts,\n",
    "        time_metrics,\n",
    "        recency_metrics,\n",
    "        engagement_patterns,\n",
    "        feature_exploration\n",
    "    ], axis=1).reset_index()\n",
    "    \n",
    "    # Fill NaN values with 0 for new users or users with missing metrics\n",
    "    log_features = log_features.fillna(0)\n",
    "    \n",
    "    return log_features\n",
    "\n",
    "\n",
    "def prepare_lead_scoring_data(df_users, df_logs, train_end_date, val_end_date):\n",
    "    df_users = df_users.copy()\n",
    "    df_logs = df_logs.copy()\n",
    "    \n",
    "    df_users['signup_date'] = pd.to_datetime(df_users['signup_date'])\n",
    "    df_logs['timestamp'] = pd.to_datetime(df_logs['timestamp'])\n",
    "    \n",
    "    train_end_date = pd.to_datetime(train_end_date)\n",
    "    val_end_date = pd.to_datetime(val_end_date)\n",
    "    \n",
    "    train_mask = df_users['signup_date'] < train_end_date\n",
    "    val_mask = (df_users['signup_date'] >= train_end_date) & (df_users['signup_date'] < val_end_date)\n",
    "    test_mask = df_users['signup_date'] >= val_end_date\n",
    "    \n",
    "    df_train = df_users[train_mask].copy()\n",
    "    df_val = df_users[val_mask].copy()\n",
    "    df_test = df_users[test_mask].copy()\n",
    "    \n",
    "    train_features = create_log_features(df_users, df_logs, train_end_date)\n",
    "    val_features = create_log_features(df_users, df_logs, val_end_date)\n",
    "    test_features = create_log_features(df_users, df_logs, df_logs['timestamp'].max())\n",
    "\n",
    "    df_train = df_train.merge(train_features, on='user_id', how='left')\n",
    "    df_val = df_val.merge(val_features, on='user_id', how='left')\n",
    "    df_test = df_test.merge(test_features, on='user_id', how='left')\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e21c5b0-a1ae-4a00-91b1-4bd3d29d469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = prepare_lead_scoring_data(\n",
    "    df_users,\n",
    "    df_logs,\n",
    "    train_end_date='2024-03-01',\n",
    "    val_end_date='2024-03-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be980606-f060-44ab-a955-465c3113fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    date_columns = ['signup_date', 'conversion_date']\n",
    "    exclude_columns = ['user_id', 'converted'] + date_columns\n",
    "\n",
    "    df = df.drop(columns=exclude_columns)\n",
    "    df = df.fillna(0)\n",
    "    feature_dict = preprocess_required_features(df)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "train_dicts = prepare_features(df_train)\n",
    "val_dicts = prepare_features(df_val)\n",
    "test_dicts = prepare_features(df_test)\n",
    "\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6baa71-cd2f-4b11-a870-f7005a1879a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579a70cb-0a8d-49b6-8548-e26f1643fc8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run rumbling-gnat-213 at: http://localhost:5000/#/experiments/1/runs/69f0a835de96443a8ef740f2a74f1e27.\n",
      "2024/11/15 10:01:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.389, Val AUC: 0.408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:05 INFO mlflow.tracking._tracking_service.client: 🏃 View run bedecked-conch-5 at: http://localhost:5000/#/experiments/1/runs/0482ea257ab64a878eb6e83d5c707454.\n",
      "2024/11/15 10:01:05 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.643, Val AUC: 0.566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run victorious-kit-657 at: http://localhost:5000/#/experiments/1/runs/9c53906e760145a58b734c0678137e42.\n",
      "2024/11/15 10:01:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=saga, penalty=l1:\n",
      "Train AUC: 0.389, Val AUC: 0.409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:10 INFO mlflow.tracking._tracking_service.client: 🏃 View run efficient-pug-388 at: http://localhost:5000/#/experiments/1/runs/03e0784c1b014dfe8ef2bdbbb7b23090.\n",
      "2024/11/15 10:01:10 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.0001, solver=saga, penalty=l2:\n",
      "Train AUC: 0.547, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:12 INFO mlflow.tracking._tracking_service.client: 🏃 View run able-gnu-877 at: http://localhost:5000/#/experiments/1/runs/639a5b7591524bab94c88bae2be2f3c6.\n",
      "2024/11/15 10:01:12 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.494, Val AUC: 0.429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:14 INFO mlflow.tracking._tracking_service.client: 🏃 View run ambitious-sloth-849 at: http://localhost:5000/#/experiments/1/runs/b0cb96df4eb3483e8fd129a598016929.\n",
      "2024/11/15 10:01:14 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.656, Val AUC: 0.592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:16 INFO mlflow.tracking._tracking_service.client: 🏃 View run inquisitive-wren-906 at: http://localhost:5000/#/experiments/1/runs/a9137e71ef8942929fd7164758ea174a.\n",
      "2024/11/15 10:01:16 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=saga, penalty=l1:\n",
      "Train AUC: 0.489, Val AUC: 0.426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:19 INFO mlflow.tracking._tracking_service.client: 🏃 View run selective-snipe-162 at: http://localhost:5000/#/experiments/1/runs/cec281121b474674857c52269e701204.\n",
      "2024/11/15 10:01:19 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.001, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:21 INFO mlflow.tracking._tracking_service.client: 🏃 View run adaptable-fowl-508 at: http://localhost:5000/#/experiments/1/runs/b3fc00c84d29458a9fa52d2a3fc0f101.\n",
      "2024/11/15 10:01:21 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.645, Val AUC: 0.583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:23 INFO mlflow.tracking._tracking_service.client: 🏃 View run awesome-shoat-336 at: http://localhost:5000/#/experiments/1/runs/522ccae62d6149dfb07ede87e0bbe24b.\n",
      "2024/11/15 10:01:23 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.685, Val AUC: 0.586\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:25 INFO mlflow.tracking._tracking_service.client: 🏃 View run wistful-snail-388 at: http://localhost:5000/#/experiments/1/runs/165e8c8695cc47c7aab67df8f022f9d1.\n",
      "2024/11/15 10:01:25 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=saga, penalty=l1:\n",
      "Train AUC: 0.543, Val AUC: 0.440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:28 INFO mlflow.tracking._tracking_service.client: 🏃 View run capricious-asp-184 at: http://localhost:5000/#/experiments/1/runs/2edaf239abd14ee4b73f1a31ba62395a.\n",
      "2024/11/15 10:01:28 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.01, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run fortunate-donkey-928 at: http://localhost:5000/#/experiments/1/runs/5d59c84332644f7cb6316a9494430064.\n",
      "2024/11/15 10:01:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.674, Val AUC: 0.603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:32 INFO mlflow.tracking._tracking_service.client: 🏃 View run incongruous-mole-345 at: http://localhost:5000/#/experiments/1/runs/31d1dec3dfed4c9bb73308560d4dfde1.\n",
      "2024/11/15 10:01:32 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.712, Val AUC: 0.560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run selective-perch-798 at: http://localhost:5000/#/experiments/1/runs/3dcfddba1b2c469aa2d21da83464bd78.\n",
      "2024/11/15 10:01:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=saga, penalty=l1:\n",
      "Train AUC: 0.547, Val AUC: 0.440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:37 INFO mlflow.tracking._tracking_service.client: 🏃 View run bemused-bug-509 at: http://localhost:5000/#/experiments/1/runs/e183c7147e154dd1a759ab8864b982d0.\n",
      "2024/11/15 10:01:37 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=0.1, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:41 INFO mlflow.tracking._tracking_service.client: 🏃 View run rogue-bug-962 at: http://localhost:5000/#/experiments/1/runs/8b52f9287c5542aabd18ee0c4c6be34f.\n",
      "2024/11/15 10:01:41 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.720, Val AUC: 0.570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:43 INFO mlflow.tracking._tracking_service.client: 🏃 View run sneaky-snake-448 at: http://localhost:5000/#/experiments/1/runs/8dd3a96fcabe4b38b3b09ffc3fb679bc.\n",
      "2024/11/15 10:01:43 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.719, Val AUC: 0.561\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:46 INFO mlflow.tracking._tracking_service.client: 🏃 View run unruly-bee-251 at: http://localhost:5000/#/experiments/1/runs/040bb922defa4a31a6ed5b493e29f8bd.\n",
      "2024/11/15 10:01:46 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=saga, penalty=l1:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:48 INFO mlflow.tracking._tracking_service.client: 🏃 View run upbeat-ram-541 at: http://localhost:5000/#/experiments/1/runs/0926c0d33629414ab74d3a6a8ab3f4ca.\n",
      "2024/11/15 10:01:48 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=1, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run redolent-midge-548 at: http://localhost:5000/#/experiments/1/runs/c8a1c4a5054d4ba8bf543dca6e48fb12.\n",
      "2024/11/15 10:01:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=liblinear, penalty=l1:\n",
      "Train AUC: 0.722, Val AUC: 0.574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:01:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:52 INFO mlflow.tracking._tracking_service.client: 🏃 View run masked-worm-572 at: http://localhost:5000/#/experiments/1/runs/0e7c362154654de2b25faa7d39fbb74f.\n",
      "2024/11/15 10:01:52 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=liblinear, penalty=l2:\n",
      "Train AUC: 0.720, Val AUC: 0.560\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run secretive-worm-634 at: http://localhost:5000/#/experiments/1/runs/1bbb00ebc12749ddb1e22383ad3add6a.\n",
      "2024/11/15 10:01:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=saga, penalty=l1:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "2024/11/15 10:01:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:01:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run stylish-crab-90 at: http://localhost:5000/#/experiments/1/runs/5cd07dd777d940069d4fa152ef3fd068.\n",
      "2024/11/15 10:01:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with C=10, solver=saga, penalty=l2:\n",
      "Train AUC: 0.548, Val AUC: 0.441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for C in param_grid['C']:\n",
    "    for solver in param_grid['solver']:\n",
    "        for penalty in param_grid['penalty']:\n",
    "            # Skip invalid combinations\n",
    "            if solver == 'liblinear' and penalty not in ['l1', 'l2']:\n",
    "                continue\n",
    "\n",
    "            # Start an MLflow run\n",
    "            with mlflow.start_run():\n",
    "                # Log parameters\n",
    "                mlflow.log_param(\"C\", C)\n",
    "                mlflow.log_param(\"solver\", solver)\n",
    "                mlflow.log_param(\"penalty\", penalty)\n",
    "\n",
    "                pipeline = make_pipeline(\n",
    "                    DictVectorizer(),\n",
    "                    LogisticRegression(\n",
    "                        C=C, \n",
    "                        solver=solver,\n",
    "                        penalty=penalty,\n",
    "                        random_state=1,\n",
    "                        max_iter=1000\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "                pipeline.fit(train_dicts, y_train)\n",
    "\n",
    "                train_pred = pipeline.predict_proba(train_dicts)[:, 1]\n",
    "                val_pred = pipeline.predict_proba(val_dicts)[:, 1]\n",
    "\n",
    "                train_auc = roc_auc_score(y_train, train_pred)\n",
    "                val_auc = roc_auc_score(y_val, val_pred)\n",
    "                \n",
    "                mlflow.log_metric(\"train_auc\", train_auc)\n",
    "                mlflow.log_metric(\"val_auc\", val_auc)\n",
    "\n",
    "                mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "                print(f\"Run with C={C}, solver={solver}, penalty={penalty}:\")\n",
    "                print(f\"Train AUC: {train_auc:.3f}, Val AUC: {val_auc:.3f}\\n\")\n",
    "\n",
    "                results.append({\n",
    "                    'C': C,\n",
    "                    'solver': solver,\n",
    "                    'penalty': penalty,\n",
    "                    'train_auc': train_auc,\n",
    "                    'val_auc': val_auc\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57439df3-7a14-4b81-9059-61150c0a630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 models by validation AUC:\n",
      "         C     solver penalty  train_auc   val_auc\n",
      "12   0.100  liblinear      l1   0.674355  0.603015\n",
      "5    0.001  liblinear      l2   0.656337  0.592494\n",
      "9    0.010  liblinear      l2   0.685496  0.586387\n",
      "8    0.010  liblinear      l1   0.645429  0.582667\n",
      "20  10.000  liblinear      l1   0.721949  0.574228\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for easy analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('val_auc', ascending=False)\n",
    "\n",
    "print(\"Top 5 models by validation AUC:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eed24e85-526c-4f1d-a148-3375509a5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      "C=0.1, solver=liblinear, penalty=l1\n",
      "Validation AUC: 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 10:08:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/15 10:08:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run best_model at: http://localhost:5000/#/experiments/1/runs/1190ba2e6a0e4214899d826b84a8ba98.\n",
      "2024/11/15 10:08:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "best_params = results_df.iloc[0]\n",
    "print(\"\\nBest parameters:\")\n",
    "print(f\"C={best_params['C']}, solver={best_params['solver']}, penalty={best_params['penalty']}\")\n",
    "print(f\"Validation AUC: {best_params['val_auc']:.3f}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"best_model\"):\n",
    "    pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            penalty=best_params['penalty'],\n",
    "            random_state=1,\n",
    "            max_iter=1000\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pipeline.fit(train_dicts, y_train)\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"C\": best_params['C'],\n",
    "        \"solver\": best_params['solver'],\n",
    "        \"penalty\": best_params['penalty']\n",
    "    })\n",
    "\n",
    "    final_train_pred = pipeline.predict_proba(train_dicts)[:, 1]\n",
    "    final_val_pred = pipeline.predict_proba(val_dicts)[:, 1]\n",
    "    final_train_auc = roc_auc_score(y_train, final_train_pred)\n",
    "    final_val_auc = roc_auc_score(y_val, final_val_pred)\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"train_auc\": final_train_auc,\n",
    "        \"val_auc\": final_val_auc\n",
    "    })\n",
    "\n",
    "    mlflow.sklearn.log_model(pipeline, \"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bf0ea47-a9f4-43e8-b87c-3ed6403c2f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features with tuned model:\n",
      "                               feature  importance  abs_importance\n",
      "38         expected_student_count=<100    0.129421        0.129421\n",
      "44                lead_source=Referral   -0.127615        0.127615\n",
      "41    lead_source=Education Conference   -0.121131        0.121131\n",
      "17            category_course_creation    0.089542        0.089542\n",
      "60  primary_use_case=Employee Training   -0.084075        0.084075\n",
      "50            organization_size=51-200    0.072476        0.072476\n",
      "20                    category_support    0.061360        0.061360\n",
      "2                 action_create_course    0.059987        0.059987\n",
      "4                  action_invite_users    0.058763        0.058763\n",
      "12           avg_hours_between_actions   -0.056850        0.056850\n"
     ]
    }
   ],
   "source": [
    "# Look at feature importance for the tuned model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': pipeline[0].feature_names_,\n",
    "    'importance': pipeline[1].coef_[0],\n",
    "    'abs_importance': np.abs(pipeline[1].coef_[0])\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('abs_importance', ascending=False)\n",
    "\n",
    "print('\\nTop 10 most important features with tuned model:')\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d4d9e1-ade7-446a-af5b-1280a3a973b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pipeline[0].feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48027f6c-c009-4924-96a1-bfb1b2b73bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Source Impact on Conversion (sorted by coefficient):\n",
      "                 source  coefficient\n",
      "0        Direct Traffic     0.000000\n",
      "2         Google Search     0.000000\n",
      "5          Social Media     0.000000\n",
      "3   Product Review Site     0.000000\n",
      "1  Education Conference    -0.121131\n",
      "4              Referral    -0.127615\n",
      "\n",
      "Lead Source Distribution in Training Data:\n",
      "lead_source\n",
      "Education Conference    326\n",
      "Product Review Site     278\n",
      "Referral                212\n",
      "Social Media            182\n",
      "Google Search           181\n",
      "Direct Traffic          149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get all features related to lead_source\n",
    "lead_source_features = [f for f in feature_names if 'lead_source=' in f]\n",
    "\n",
    "# Get their coefficients\n",
    "lead_source_coef = pd.DataFrame({\n",
    "    'feature': lead_source_features,\n",
    "    'coefficient': pipeline[1].coef_[0][np.where([f in lead_source_features for f in feature_names])[0]]\n",
    "})\n",
    "\n",
    "# Sort by coefficient value to see most positive to most negative impact\n",
    "lead_source_coef = lead_source_coef.sort_values('coefficient', ascending=False)\n",
    "\n",
    "# Strip the 'lead_source=' prefix for cleaner display\n",
    "lead_source_coef['source'] = lead_source_coef['feature'].str.replace('lead_source=', '')\n",
    "\n",
    "print(\"Lead Source Impact on Conversion (sorted by coefficient):\")\n",
    "print(lead_source_coef[['source', 'coefficient']])\n",
    "\n",
    "# You might also want to see the distribution of lead sources in your data\n",
    "print(\"\\nLead Source Distribution in Training Data:\")\n",
    "print(df_train['lead_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448436ef-6e52-4abb-86e1-ee9447459c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
